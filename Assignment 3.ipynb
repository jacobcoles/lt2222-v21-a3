{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LT2222 V21 Assignment 3 -- Predict Swedish Vowels\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The written Swedish language has the following inventory of lowercase vowels characters: a, e, i, o, u, y, å¸ ä, ö, é.  The Evil Vowel Fairy is threatening to magically steal the vowels from Swedish texts, replacing them with blank symbols.  Before the Fairy does that, your mission is to create a system that automatically puts the vowels back, rendering the evil plan fruitless.  The most important text that the Evil Vowel Fairy is targeting are a group of newspaper articles written in the 19th century currently hosted by Språkbanken, because the Evil Vowel Fairy has some deranged plan involving the 19th century.\n",
    "\n",
    "(These newspaper articles have a bunch of other, now-archaic or foreign vowels that the Fairy is not interested in and you will ignore.)\n",
    "\n",
    "There is a secret agent who has helped by writing some scripts to train a vowel prediction model, but that agent has written the scripts a little cryptically to make it hard for the Fairy, who doesn't really understand computers but it never hurts to make sure.\n",
    "\n",
    "Every part of this assignment that involves Python scripting needs to be done on the bash command line on mltgpu or eduserv.  Include your name in README.md.\n",
    "\n",
    "This assignment is due Monday, March 29, 2021 at 9:00.  There are 31 points on this assignment, plus opportunity for 22 bonus points.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Fork and clone the GitHub repository: https://github.com/asayeed/lt2222-v21-a3 (Links to an external site.)\n",
    "\n",
    "There will be three files, train.py, model.py, and README.md.  You will write your responses to whatever needs text responses plus other comments and instructions in README.md.\n",
    "\n",
    "The texts are available at\n",
    "\n",
    "* /home/xsayas@GU.GU.SE/scratch/lt2222-v21-resources/svtrain.lower.txt -- training\n",
    "* /home/xsayas@GU.GU.SE/scratch/lt2222-v21-resources/svtest.lower.txt -- test/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Figure out train.py (8 points)\n",
    "\n",
    "train.py is already complete, and you will not modify it. Instead, in README.md, you will explain what the functions a, b, and g do, as well as the meaning of the command-line arguments that are being processed via the argparse module.\n",
    "\n",
    "You will then run train.py on the training file.  train.py will save a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: Write eval.py (15 points)\n",
    "\n",
    "Write eval.py and add it to the repository.  What eval.py will do from the command line:\n",
    "\n",
    "* Load a model produced by train.py. (Take a look at model.py.)\n",
    "* Load the test data.\n",
    "* Create evaluation instances compatible with the training instances.  (A simplifying assumption for the purposes of the assignment: assuming that the neighbouring vowels are known as though the Fairy hadn't stolen them.)\n",
    "* Use the model to predict instances.\n",
    "* Write the text with the predicted (as opposed to the real) vowels back into an output file.\n",
    "* Print the accuracy of the model to the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "os.environ[\"USE_CPU\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import train\n",
    "import torch\n",
    "\n",
    "vowels = sorted(['y', 'é', 'ö', 'a', 'i', 'å', 'u', 'ä', 'e', 'o'])\n",
    "\n",
    "def split_file_to_chars(file):\n",
    "    chars = []\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            chars += [c for c in line]\n",
    "\n",
    "    chars = [\"<s>\", \"<s>\"] + chars + [\"<e>\", \"<e>\"]\n",
    "    return chars, list(set(chars))\n",
    "\n",
    "def chars_to_file_w_vowel_replacement(chars, new_vowels, file_out):\n",
    "    all_text = str()\n",
    "    \n",
    "    for v in range(len(chars) - 4): \n",
    "        new_vowel_index = 0\n",
    "        if chars[v+2] not in vowels:\n",
    "            all_text += chars[v+2]\n",
    "            continue\n",
    "        all_text += vowels[new_vowels[new_vowel_index]]\n",
    "        new_vowel_index += 1\n",
    "    \n",
    "    f = open(file_out, \"w\")\n",
    "    f.write(all_text)\n",
    "    f.close()\n",
    "\n",
    "def create_one_hot(char, unique_chars):\n",
    "    hot_vector = np.zeros(len(unique_chars))\n",
    "    try:\n",
    "        hot_vector[unique_chars.index(char)] = 1\n",
    "    except:\n",
    "        pass\n",
    "    return hot_vector\n",
    "\n",
    "def vowel_w_context(chars, unique_chars):\n",
    "    vowels_current = []\n",
    "    vowel_contexts = []\n",
    "    for v in range(len(chars) - 4): \n",
    "        if chars[v+2] not in vowels:\n",
    "            continue\n",
    "        \n",
    "        vowel_current = vowels.index(chars[v+2])\n",
    "        vowels_current.append(vowel_current)\n",
    "        vowel_context = np.concatenate([create_one_hot(char, unique_chars) for char in [chars[v], chars[v+1], chars[v+3], chars[v+4]]])\n",
    "        vowel_contexts.append(vowel_context)\n",
    "\n",
    "    return np.array(vowel_contexts), np.array(vowels_current) #returns numpy arrays gr, which is a list one-hot-encodes of the context of each vowel, and gt which is a list of the vowels themselves represented as an index on vowels.\n",
    "        \n",
    "\n",
    "\n",
    "train_file_path = \"/home/guscoleja@GU.GU.SE/ass3/data_files/svtrain.lower.txt\"\n",
    "test_file_path = \"/home/guscoleja@GU.GU.SE/ass3/data_files/svtest.lower.txt\"\n",
    "model_file_path = \"/home/guscoleja@GU.GU.SE/ass3/lt2222-v21-a3/outfile\"\n",
    "\n",
    "\n",
    "train_chars, train_unique_chars = split_file_to_chars(train_file_path)\n",
    "train_X, train_y = vowel_w_context(train_chars, train_unique_chars)\n",
    "\n",
    "test_chars, __test_unique_chars = split_file_to_chars(test_file_path)\n",
    "test_X, test_y = vowel_w_context(test_chars, train_unique_chars)\n",
    "    \n",
    "model = torch.load(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VowelModel(\n",
       "  (lin1): Linear(in_features=452, out_features=200, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (lin2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (lin3): Linear(in_features=200, out_features=10, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66282, 452])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_t = torch.LongTensor(test_X)\n",
    "test_X_t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([264368, 452])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_t = torch.LongTensor(train_X)\n",
    "train_X_t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        3\n",
      "1        9\n",
      "2        0\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "66277    4\n",
      "66278    8\n",
      "66279    2\n",
      "66280    3\n",
      "66281    9\n",
      "Length: 66282, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "outputs = model(test_X_t.float().unsqueeze(0))\n",
    "    \n",
    "predictions = pd.Series(outputs.squeeze(0).argmax(dim=1).numpy())\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11852388280377779\n"
     ]
    }
   ],
   "source": [
    "accuracy = len(test_y[predictions == test_y]) / len(test_y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_file_w_vowel_replacement(test_chars, predictions, 'predicted_vowels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Analysis (8 points)\n",
    "                                                                      \n",
    "Describe what you do in README.md.  Train and evaluate the following models:\n",
    "\n",
    "* Five different variations of the --k option, holding the --r option at its default.\n",
    "* Five different variations of the --r option, holding the --k option at its default.\n",
    "\n",
    "Include the best model and output text in your repository with its parameters.  Describe any patterns you see, if there are any.  Look at the output texts and make qualitative comments on the performances of the model.\n",
    "\n",
    "It is very likely that in this very simple model, for this amount of data, nothing will work very well.  Nevertheless, do your best to draw whatever tentative conclusions you can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Part A: Perplexity (4 points)\n",
    "                                                                      \n",
    "Add the option in the eval.py script to compute the perplexity of the model.  Document in README.md and include perplexity values for the experiments in part 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Part B: Sequence (15 points)\n",
    "                                                                      \n",
    "Include new versions of train.py, model.py, and eval.py that do not include the assumption that neighbouring vowels are known, but rather works in sequence so that the model-predicted previous vowels are known, but future vowels are not. Systematically evaluate accuracy and describe in README.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Part C: Dropout (3 points)\n",
    "                                                                      \n",
    "Make a new version of model.py (and corresponding train.py and eval.py as necessary) that includes dropout in the model.  Systematically evaluate accuracy and describe in README.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
